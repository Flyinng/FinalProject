<h1>
  <a href="https://www.google.com/"> <img src="img/robin-logo.png" width="40%"> </a>
</h1>

<h1> Descri√ß√£o ‚öô </h1>

<p> Robin √© um website que visa ajudar as pessoas na hora de escolher as pe√ßas para montar seu computador, o Robin re√∫ne dados de diversos sites de venda de produtos de inform√°tica, retornando os valores mais acess√≠veis. </p>

<h1> Ferramentas Utilizadas üõ† </h1>

- Selenium <a href="https://selenium.dev"><img src="https://selenium.dev/images/selenium_logo_square_green.png" width="25" alt="Selenium"/></a>
- MySQL <a href="https://selenium.dev"><img src="https://kinsta.com/wp-content/uploads/2019/04/mysql-logo-1.svg" width="43" alt="MySQL"/></a>
- Python <a href="https://selenium.dev"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Python.svg/1200px-Python.svg.png" width="23" alt="MySQL"/></a>

<h1> Web-Scraping </h1>

<p> A maneira que achamos para pegar todos os dados de pe√ßas de computador foi por meio do <strong>Web-Scraping</strong>, que √© uma forma de minera√ß√£o no qual nos permite a extra√ß√£o de dados de sites da web convertendo-os em informa√ß√£o estruturada para posterior an√°lise, o framework ultilizado para obter esses dados foi o <strong>Selenium</strong> em <strong>Python</strong> </p>
<p> Cada site possui uma estrutura especifica para seus dados: </p>

<h2> Pichau </h2>

<p> A <strong>Pichau</strong> com certeza foi o site que mais tivemos dificuldade, a estrutura do site altera a cada computador diferente que o mesmo √© aberto, ent√£o uma forma que achamos para obter os dados em diferentes computadores que execut√°ssemos o c√≥digo e ele ainda funcionasse, foi usando a <strong>lib Socket</strong> para salvar uma estrutura espec√≠fica para cada IP. </p>

```python
import socket
    hostIP = socket.gethostname()           # IP Local
    IP = socket.gethostbyname(hostIP)       # Specif IP
```

<p> Outro problema que n√≥s tivemos, foi o pequeno efeito de <strong>fade-in</strong> que √© aplicado apartir da terceira linha de produtos do site, sendo assim as imagens dos √≠tens s√≥ passam a aparecer no <strong>source HMTL</strong> do site depois que voc√™ da scoll pra baixo. </p>

<img src="img/robin.gif" width="50%">

<p> Para resolver esse problema, n√≥s ultilizamos um comando do <strong>Selenium</strong> para pegar a altura total do site, e para fazer ele dar um scroll down autom√°tico de acordo com o tamanho do site. </p>

```python
from selenium import webdriver
    height = driver.execute_script("return document.body.scrollHeight") 
    while scroll < height:
         driver.execute_script(f"window.scrollTo(0, {scroll});")
         scroll += 200
```
<p> Problemas resolvidos, agora vem a hora de pegar cada especifica√ß√£o de pe√ßa, como o pre√ßo, o nome, etc... </p>
<p> Tendo isso em mente, optamos na Pichau essa lista de especifica√ß√µes:</p>

| Especifica√ß√µes | Dados |
| --- | --- |
| Pre√ßo parcelado | R$ 771,29 |
| Pre√ßo | R$678,74 |
| Nome | MEMORIA TEAM GROUP T-FORCE DELTA RGB, 8GB(1X8GB), DDR4, 3200MHZ, C16, BRANCO, TF4D48G3200HC16C01 |
| Link | https://www.pichau.com.br/memoria-team-group-t-force-delta-rgb-8gb-1x8gb-ddr4-3200mhz-c16-branco-tf4d48g3200hc16c01 |
| Link da imagem | https://media.pichau.com.br/media/catalog/product/cache/2f958555330323e505eba7ce930bdf27/t/f/tf4d48g3200hc16c011.jpg |
| Hor√°rio de Scraping | 09/07/2022 23:22:34 |

<h3> Como realizar o <strong>scraping</strong> na Pichau </h3>

<table>
  <tr>
    <td>Bloco de informa√ß√£o </td>
     <td>C√≥digo de web-scraping</td>
     <td>Explica√ß√£o</td>
  </tr>
  <tr>
    <td valign="top"><img src="img/Captura de tela 2022-09-10 224901.jpg" width="200%"></td>
    <td valign="top">
    
```python
# Crawling Products == Name
product = driver.find_elements('tag name', 'h2')
for i in product:
    if i.text == "":
        continue
    namesProducts.append(i.text)
``` 

</td>
<td valign="top">

No site da Pichau os t√≠tulos dos produtos s√£o separados em tags ``h2``, sendo assim temos que puxar todas as tags h2 do site usando
``find_elements('tag name', 'h2')``

</td>
  <tr>
    <td valign="top"><img src="img/Captura de tela 2022-09-10 224901.jpg" width="200%"></td>
    <td valign="top">
    
```python
# Crawling Products == Image
while scroll < height:
    driver.execute_script(f"window.scrollTo(0, {scroll});")
    product = driver.find_elements('tag name', 'img')
    for e in product:
        if 'product' in e.get_attribute('src'):
            imgProducts.append(e.get_attribute('src'))
    scroll += 200
imgProducts = list(dict.fromkeys(imgProducts))
``` 

</td>
<td valign="top">

  As imagens dos produtos s√£o separados em tags ``img`` devido ao problema do <strong>fade-in</strong> explicado acima. Temos que usar um comando  ``driver.execute_script(f"window.scrollTo(0, {scroll});")`` dentro de um la√ßo ``` while ``` para que o c√≥digo fique dando scrap e descendo, depois temos separar as imagens dos produtos usando: 
```python
for e in product:
        if 'product' in e.get_attribute('src'):
            imgProducts.append(e.get_attribute('src'))
``` 

</td>
<td valign="top">

No site da Pichau os t√≠tulos dos produtos s√£o separados em tags ``h2``, sendo assim temos que puxar todas as tags h2 do site usando
``find_elements('tag name', 'h2')``

</td>
  <tr>
    <td valign="top"><img src="img/Captura de tela 2022-09-10 224901.jpg" width="200%"></td>
    <td valign="top">
    
```python
# Crawling Products == Image
while scroll < height:
    driver.execute_script(f"window.scrollTo(0, {scroll});")
    product = driver.find_elements('tag name', 'img')
    for e in product:
        if 'product' in e.get_attribute('src'):
            imgProducts.append(e.get_attribute('src'))
    scroll += 200
imgProducts = list(dict.fromkeys(imgProducts))
``` 

</td>
<td valign="top">

  As imagens dos produtos s√£o separados em tags ``img`` devido ao problema do <strong>fade-in</strong> explicado acima. Temos que usar um comando  ``driver.execute_script(f"window.scrollTo(0, {scroll});")`` dentro de um la√ßo ``` while ``` para que o c√≥digo fique dando scrap e descendo, depois temos separar as imagens dos produtos usando: 
```python
for e in product:
        if 'product' in e.get_attribute('src'):
            imgProducts.append(e.get_attribute('src'))
``` 

</td>
<td valign="top">

No site da Pichau os t√≠tulos dos produtos s√£o separados em tags ``h2``, sendo assim temos que puxar todas as tags h2 do site usando
``find_elements('tag name', 'h2')``

</td>
  <tr>
    <td valign="top"><img src="img/Captura de tela 2022-09-10 224901.jpg" width="200%"></td>
    <td valign="top">
    
```python
# Crawling Products == Image
while scroll < height:
    driver.execute_script(f"window.scrollTo(0, {scroll});")
    product = driver.find_elements('tag name', 'img')
    for e in product:
        if 'product' in e.get_attribute('src'):
            imgProducts.append(e.get_attribute('src'))
    scroll += 200
imgProducts = list(dict.fromkeys(imgProducts))
``` 

</td>
<td valign="top">

  As imagens dos produtos s√£o separados em tags ``img`` devido ao problema do <strong>fade-in</strong> explicado acima. Temos que usar um comando  ``driver.execute_script(f"window.scrollTo(0, {scroll});")`` dentro de um la√ßo ``` while ``` para que o c√≥digo fique dando scrap e descendo, depois temos separar as imagens dos produtos usando: 
```python
for e in product:
        if 'product' in e.get_attribute('src'):
            imgProducts.append(e.get_attribute('src'))
``` 

</td>
 </table>
 
<br>
<h2>
UNDER DEVELOPMENT
</h2>
<br>
üìúProject developed in the <a href="https://www.entra21.com.br/">Entra21</a> Python Class
